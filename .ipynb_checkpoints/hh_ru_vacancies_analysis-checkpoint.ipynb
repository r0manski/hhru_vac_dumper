{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consuming HH.RU API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import http.client\n",
    "import datetime\n",
    "import json\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Providing headers as recomennded in API Documentation\n",
    "headers = {\"User-Agent\": \"HH-User-Agent\"}\n",
    "\n",
    "#function to get all the related vacancy ids\n",
    "def get_vacancy_ids(keyword):\n",
    "    vacancy_ids = []\n",
    "    conn = http.client.HTTPSConnection(\"api.hh.ru\")\n",
    "    per_page = 100 #100 is a maximum allowed by API\n",
    "    page = 0\n",
    "    count = per_page\n",
    "    date_from = (datetime.datetime.now() - datetime.timedelta(days=29)).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    date_to = datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    area_id = 113 #Russia\n",
    "    \n",
    "    while count == per_page:\n",
    "        path = (\"/vacancies?text={}&area={}&per_page={}&date_from={}&date_to={}&page={}\"\n",
    "                .format(keyword,area_id,per_page, date_from, date_to, page))\n",
    "        \n",
    "        conn.request(\"GET\", path, headers=headers)\n",
    "        resp = conn.getresponse()\n",
    "        if resp.status != 200:\n",
    "        # something went wrong\n",
    "            raise ValueError('API error happened.')\n",
    "        vacancies = resp.read()\n",
    "        conn.close()\n",
    "\n",
    "        count = len(json.loads(vacancies)['items'])\n",
    "        page = page+1\n",
    "        for item in json.loads(vacancies)['items']:\n",
    "            vacancy_ids.append(item['id'])\n",
    "    return vacancy_ids\n",
    "\n",
    "\n",
    "#function to retrieve vacancy description by vacancy id and save it to a txt file.\n",
    "def get_vacancies(vacancy_ids, ):\n",
    "    for vac_id in vacancy_ids:\n",
    "        conn = http.client.HTTPSConnection(\"api.hh.ru\")\n",
    "        conn.request(\"GET\", \"/vacancies/{}\".format(vac_id), headers=headers)\n",
    "        resp = conn.getresponse()\n",
    "        if resp.status != 200:\n",
    "        # something went wrong\n",
    "            raise ValueError('API error happened.')\n",
    "        vacancy_txt = resp.read()\n",
    "        conn.close()\n",
    "        vacancy = json.loads(vacancy_txt)\n",
    "        #cleaning description out of html tags and other irrelevant charachters\n",
    "        clean_desc = ''\n",
    "        desc = re.sub('<[^>]*>', '', vacancy['description'].lower())\n",
    "        desc = re.sub('ur[^a-zа-я]+', ' ', desc, re.UNICODE)        \n",
    "        words = desc.split()\n",
    "        for word in words:\n",
    "                    if len(word.strip()) > 2:\n",
    "                        clean_desc = desc + \" \" + word\n",
    "        \n",
    "        with open('corpus.txt', 'a') as f:\n",
    "            f.write(\" \" + clean_desc)\n",
    "            f.close\n",
    "    print('file corpus.txt with vacancies descriptions is created in the working directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = get_vacancy_ids(\"Data+Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "print (len(ids)) #print number of vacancies\n",
    "#get_vacancies(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24669691'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file corpus.txt with vacancies descriptions is created in the working directory\n"
     ]
    }
   ],
   "source": [
    "get_vacancies([24669691])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "document_text = open('corpus.txt', 'r')\n",
    "text_string = document_text.read()\n",
    "#match_pattern = re.findall(r'\\b[a-zа-я]{3,15}\\b', text_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' обязанности:  написание скриптов для парсинга данных из различных статистических баз; составление словарей для объединения данных в единую таблицу; разработка и реализация методологии восстановления пропусков и определения статистических выбросов.  требования:  python (pandas, requests, threading); sql, умение составлять запросы к бд; понимание статистики; знания английского, достаточные для чтения документации и поиска информации на иностранных сайтах; ms excel.  условия:  полная занятость, полный рабочий день с 9 до 18; офис м. дмитровская, бц «савеловский-сити»; оформление по тк рф; молодой дружный коллектив, доброжелательная атмосфера; много амбициозных задач.    откликнувшимся кандидатам будет предложено небольшое тестовое задание, которое отражает суть работы. заработная плата обсуждается с успешным кандидатом. просьба указывать желаемый уровень заработной платы при выполнении тестового задания. задания.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match_pattern = re.findall(r'\\b[a-z]{3,15}\\b', text_string)\n",
    " \n",
    "for word in match_pattern:\n",
    "    count = frequency.get(word,0)\n",
    "    frequency[word] = count + 1\n",
    "     \n",
    "frequency_list = frequency.keys()\n",
    " \n",
    "for words in frequency_list:\n",
    "    print words, frequency[words]\n",
    "#wordlist = wordstring.split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
